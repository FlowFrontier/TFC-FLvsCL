{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b901eaf",
   "metadata": {},
   "source": [
    "# Preliminaries and helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd55b5e",
   "metadata": {},
   "source": [
    "## Measure flows via NFStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efff8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nfstream\n",
    "import sys\n",
    "from nfstream import NFPlugin\n",
    "\n",
    "print(nfstream.__version__)\n",
    "\n",
    "class TCP_expiration(NFPlugin):\n",
    "\n",
    "    def on_init(self, packet, flow):\n",
    "        \"\"\"Init function to handle packets.\"\"\"\n",
    "        if packet.rst or packet.fin:\n",
    "            flow.expiration_id = -1\n",
    "\n",
    "    def on_update(self, packet, flow):\n",
    "        \"\"\"Update function to handle packets.\"\"\"\n",
    "        if packet.rst or packet.fin:\n",
    "            flow.expiration_id = -1\n",
    "\n",
    "# only process ipv4 or ipv6 tcp and udp traffic\n",
    "bpf = \"(ip proto \\\\tcp or \\\\udp) or (ip6 proto \\\\tcp or \\\\udp)\"  \n",
    "\n",
    "if __name__ == '__main__':  # Mandatory if you are running on Windows Platform\n",
    "    path = sys.argv[1]\n",
    "    print(\"nfstream processing started. Use Ctrl+C to interrupt and save.\")\n",
    "    total_flows = nfstream.NFStreamer(source=path\n",
    "                                      , decode_tunnels = True\n",
    "                                      , statistical_analysis= True\n",
    "                                      , splt_analysis=0\n",
    "                                      , idle_timeout= 120\n",
    "                                      , active_timeout= 1800\n",
    "                                      , performance_report=1\n",
    "                                      , udps=TCP_expiration()\n",
    "                                      , bpf_filter=bpf\n",
    "                                      ).to_csv(flows_per_file=2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed09f2",
   "metadata": {},
   "source": [
    "## Combine all CSVs into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95ca362",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '(NR == 1) || (FNR > 1)' *.csv > combined.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd5ad9",
   "metadata": {},
   "source": [
    "## Measurement stats\n",
    "\n",
    "Total flows collected: 50,000,000\n",
    "\n",
    "First flow collected at 1689779893668 = Wednesday, 19 July 2023 17:18:13.668 GMT+02:00 DST\n",
    "\n",
    "Last flow collected at 1689827196977 = Thursday, 20 July 2023 06:26:36.977 GMT+02:00 DST\n",
    "\n",
    "The difference between the two epoch times is 13:02:53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94466af5",
   "metadata": {},
   "source": [
    "## Show column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head combined.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4145b",
   "metadata": {},
   "source": [
    "## Drop columns with no value for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b405813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns with no.\n",
    "!cut -d, -f 2,11,12,14,17-19,22-24,27-53,54-77,78-81 combined.csv > filtered1.csv\n",
    "\n",
    "# More elegant but SLOWER ways:\n",
    "\n",
    "# awk -F, -v OFS=',' '\n",
    "#     NR==1 {\n",
    "#         for(i=1; i<=NF; i++) {\n",
    "#             if ($i ~ /(.*first_seen.*|.*last_seen.*|id|expiration_id|requested_server_name|client_fingerprint|server_fingerprint|user_agent|content_type|src_ip|src_mac|dst_ip|dst_mac|src_oui|dst_oui|ip_version|vlan_id|tunnel_id|src_port|dst_port|protocol)$/) {\n",
    "#                 cols[i]\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "#     {\n",
    "#         sep = \"\"\n",
    "#         for(i=1; i<=NF; i++) {\n",
    "#             if (!(i in cols)) {\n",
    "#                 printf \"%s%s\", sep, $i\n",
    "#                 sep = OFS\n",
    "#             }\n",
    "#         }\n",
    "#         printf ORS\n",
    "#     }\n",
    "# ' combined.csv > pruned.csv\n",
    "\n",
    "\n",
    "# csvcut -C 'id,expiration_id,requested_server_name,client_fingerprint,server_fingerprint,user_agent,content_type,src_ip,src_mac,dst_ip,dst_mac,src_oui,dst_oui,ip_version,vlan_id,tunnel_id,src_port,dst_port,protocol,first_seen,last_seen' combined.csv > pruned.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084d1be",
   "metadata": {},
   "source": [
    "## Filter out flows with low label accuracy and unknown labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of all the flows where labeling confidence via nDPI is not maximum (6) \\\n",
    "# and also those flows where the label is \"Unknown\"\n",
    "!awk -F, 'BEGIN{OFS=\",\"} {if (NR==1 || ($NF == 6 && $(NF-1) == 0 && $(NF-3) != \"Unknown\")) print $0}' filtered1.csv > filtered2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f703d",
   "metadata": {},
   "source": [
    "## Get rid of the last 3 columns as we do not need them anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f6e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cut -d, -f 1-62 filtered2.csv > filtered3.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8544b9",
   "metadata": {},
   "source": [
    "## Filter out flows whose packet count is lower than 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137649f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk -F, 'BEGIN{OFS=\",\"} {if (NR==1 || $6 >= 20) print $0}' filtered3.csv > filtered4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b01bd28",
   "metadata": {},
   "source": [
    "## Show number of unique application types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bedb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk -F ',' 'NR>1{print $(NF)}' filtered4.csv | sort | uniq -c | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47a9d4",
   "metadata": {},
   "source": [
    "## Keep a subset of application types for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk -F, 'BEGIN{OFS=\",\"} \n",
    "    NR == 1 || \n",
    "    $NF == \"\\\"QUIC.YouTube\\\"\" || \n",
    "    $NF == \"\\\"QUIC.Facebook\\\"\" || \n",
    "    $NF == \"\\\"TLS.TikTok\\\"\" || \n",
    "    $NF == \"\\\"TLS.Apple\\\"\" || \n",
    "    $NF == \"\\\"Discord\\\"\" || \n",
    "    $NF == \"\\\"BitTorrent\\\"\" || \n",
    "    $NF == \"\\\"STUN\\\"\" || \n",
    "    $NF == \"\\\"HTTP\\\"\" || \n",
    "    $NF == \"\\\"SSH\\\"\" || \n",
    "    $NF == \"\\\"WhatsApp\\\"\" {print $0}' filtered4.csv > filtered5.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
